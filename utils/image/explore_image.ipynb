{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34mAutoDL_ingestion_program\u001b[m\u001b[m/      README.md\r\n",
      "\u001b[1m\u001b[34mAutoDL_sample_code_submission\u001b[m\u001b[m/ metadata\r\n",
      "\u001b[1m\u001b[34mAutoDL_sample_data\u001b[m\u001b[m/            run_local_test.py\r\n",
      "\u001b[1m\u001b[34mAutoDL_scoring_program\u001b[m\u001b[m/\r\n"
     ]
    }
   ],
   "source": [
    "%ls ../../../autodl/codalab_competition_bundle/AutoDL_starting_kit/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_dir = '../../formatted_datasets/'\n",
    "dataset_name = 'munster'\n",
    "train_dir = os.path.join(input_dir, '{}/{}.data/train'.format(dataset_name, dataset_name))\n",
    "test_dir = os.path.join(input_dir, '{}/{}.data/test'.format(dataset_name, dataset_name))\n",
    "starting_kit_dir = '../../../autodl/codalab_competition_bundle/AutoDL_starting_kit/'\n",
    "ingestion_dir = os.path.join(starting_kit_dir, 'AutoDL_ingestion_program/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(ingestion_dir)\n",
    "from dataset import AutoDLDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Number of training files: 1.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Label: 5')"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAEICAYAAACQ6CLfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n1P8BXjraSnmbdZgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12f37e7b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_dir = train_dir\n",
    "autodl_dataset = AutoDLDataset(dataset_dir)\n",
    "dataset = autodl_dataset.get_dataset()\n",
    "iterator = dataset.make_one_shot_iterator()\n",
    "next_element = iterator.get_next()\n",
    "with tf.Session() as sess:\n",
    "  features, labels = sess.run(next_element)\n",
    "image = features.reshape(28,28)\n",
    "label = np.argmax(labels)\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.title('Label: {}'.format(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Number of training files: 1.\n",
      "Looking at example of index: 379\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Label: 4')"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAEICAYAAACQ6CLfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n5fCbJeXwmyXl8Jsl5fCbJfW/IyZJq6nF+xAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1342c8710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_dir = test_dir\n",
    "autodl_dataset = AutoDLDataset(dataset_dir, repeat=False)\n",
    "dataset = autodl_dataset.get_dataset()\n",
    "num_examples_test = autodl_dataset.get_metadata().size()\n",
    "index = np.random.randint(0, num_examples_test)\n",
    "index = np.random.randint(0, 1000)\n",
    "print('Looking at example of index: {}'.format(index))\n",
    "iterator = dataset.make_one_shot_iterator()\n",
    "next_element = iterator.get_next()\n",
    "with tf.Session() as sess:\n",
    "  for i in range(index + 1):\n",
    "    features, _ = sess.run(next_element)\n",
    "solution_dir = os.path.join(input_dir, 'munster/munster.solution')\n",
    "labels = np.loadtxt(solution_dir)\n",
    "image = features.reshape(28,28)\n",
    "label = np.argmax(labels, axis=1)[index]\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.title('Label: {}'.format(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fine_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fine_labels[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Number of training files: 1.\n",
      "Looking at example of index: 577\n",
      "11 38\n",
      "[11 58]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Label: large_omnivores_and_herbivores - kangaroo')"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUIAAACACAYAAAB++mCXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMhkU4N2EYgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12b974eb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_name = 'ciao'\n",
    "train_dir = os.path.join(input_dir, '{}/{}.data/train'.format(dataset_name, dataset_name))\n",
    "test_dir = os.path.join(input_dir, '{}/{}.data/test'.format(dataset_name, dataset_name))\n",
    "dataset_dir = test_dir\n",
    "data_dict = test_dict\n",
    "coarse_labels = data_dict[b'coarse_labels']\n",
    "fine_labels = data_dict[b'fine_labels']\n",
    "autodl_dataset = AutoDLDataset(dataset_dir, repeat=False)\n",
    "dataset = autodl_dataset.get_dataset()\n",
    "num_examples_test = autodl_dataset.get_metadata().size()\n",
    "# index = np.random.randint(0, num_examples_test)\n",
    "index = np.random.randint(0, 1000)\n",
    "# index = 0\n",
    "print('Looking at example of index: {}'.format(index))\n",
    "coarse_label = coarse_labels[index]\n",
    "fine_label = fine_labels[index]\n",
    "coarse_label_name = coarse_label_names[coarse_label]\n",
    "fine_label_name = fine_label_names[fine_label]\n",
    "iterator = dataset.make_one_shot_iterator()\n",
    "next_element = iterator.get_next()\n",
    "with tf.Session() as sess:\n",
    "  for i in range(index + 1):\n",
    "    features, _ = sess.run(next_element)\n",
    "image = features.reshape(32,32)\n",
    "solution_dir = os.path.join(input_dir, '{}/{}.solution'.format(dataset_name, dataset_name))\n",
    "labels = np.loadtxt(solution_dir)\n",
    "label = np.where(labels[index] > 0)[0]\n",
    "print(coarse_label, fine_label)\n",
    "print(label)\n",
    "plt.figure(figsize=(1.5,1.5))\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.title('Label: {} - {}'.format(coarse_label_name, fine_label_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "haha = {'yo':1, 'juhua':2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"{'yo': 1, 'juhua': 2}\""
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(haha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.contrib.learn.python.learn.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-93-f63d704db7b6>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /Users/evariste/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /Users/evariste/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use urllib or similar directly.\n",
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "WARNING:tensorflow:From /Users/evariste/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "WARNING:tensorflow:From /Users/evariste/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/evariste/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "datasets = mnist.read_data_sets(train_dir='/tmp/data/', validation_size=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
      "Training data size: (60000, 784)\n",
      "Validation data size: (0, 784)\n",
      "Test data size: (10000, 784)\n"
     ]
    }
   ],
   "source": [
    "datasets = mnist.read_data_sets(train_dir='/tmp/data/', validation_size=0)\n",
    "print(\"Training data size:\", datasets.train.images.shape)\n",
    "print(\"Validation data size:\", datasets.validation.images.shape)\n",
    "print(\"Test data size:\", datasets.test.images.shape)\n",
    "\n",
    "tf.gfile.MkDir(\"mnist/\")\n",
    "\n",
    "input_sequence = datasets.train.images\n",
    "output_sequence = datasets.train.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sequence.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "haha = zip(input_sequence, output_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.01176471, 0.07058824, 0.07058824,\n",
      "       0.07058824, 0.49411768, 0.53333336, 0.6862745 , 0.10196079,\n",
      "       0.6509804 , 1.        , 0.9686275 , 0.49803925, 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.11764707, 0.14117648, 0.36862746, 0.6039216 ,\n",
      "       0.6666667 , 0.9921569 , 0.9921569 , 0.9921569 , 0.9921569 ,\n",
      "       0.9921569 , 0.882353  , 0.6745098 , 0.9921569 , 0.9490197 ,\n",
      "       0.76470596, 0.2509804 , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.19215688, 0.9333334 ,\n",
      "       0.9921569 , 0.9921569 , 0.9921569 , 0.9921569 , 0.9921569 ,\n",
      "       0.9921569 , 0.9921569 , 0.9921569 , 0.9843138 , 0.3647059 ,\n",
      "       0.32156864, 0.32156864, 0.21960786, 0.15294118, 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.07058824, 0.8588236 , 0.9921569 , 0.9921569 ,\n",
      "       0.9921569 , 0.9921569 , 0.9921569 , 0.77647066, 0.7137255 ,\n",
      "       0.9686275 , 0.9450981 , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.3137255 , 0.6117647 , 0.41960788, 0.9921569 , 0.9921569 ,\n",
      "       0.80392164, 0.04313726, 0.        , 0.16862746, 0.6039216 ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.05490196,\n",
      "       0.00392157, 0.6039216 , 0.9921569 , 0.3529412 , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.54509807,\n",
      "       0.9921569 , 0.74509805, 0.00784314, 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.04313726, 0.74509805, 0.9921569 ,\n",
      "       0.27450982, 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.13725491, 0.9450981 , 0.882353  , 0.627451  ,\n",
      "       0.42352945, 0.00392157, 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.31764707, 0.94117653, 0.9921569 , 0.9921569 , 0.4666667 ,\n",
      "       0.09803922, 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.1764706 ,\n",
      "       0.7294118 , 0.9921569 , 0.9921569 , 0.5882353 , 0.10588236,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.0627451 , 0.3647059 ,\n",
      "       0.98823535, 0.9921569 , 0.73333335, 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.97647065, 0.9921569 ,\n",
      "       0.97647065, 0.2509804 , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.18039216, 0.50980395,\n",
      "       0.7176471 , 0.9921569 , 0.9921569 , 0.8117648 , 0.00784314,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.15294118,\n",
      "       0.5803922 , 0.8980393 , 0.9921569 , 0.9921569 , 0.9921569 ,\n",
      "       0.9803922 , 0.7137255 , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.09411766, 0.44705886, 0.86666673, 0.9921569 , 0.9921569 ,\n",
      "       0.9921569 , 0.9921569 , 0.78823537, 0.30588236, 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.09019608, 0.25882354, 0.8352942 , 0.9921569 ,\n",
      "       0.9921569 , 0.9921569 , 0.9921569 , 0.77647066, 0.31764707,\n",
      "       0.00784314, 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.07058824, 0.67058825, 0.8588236 ,\n",
      "       0.9921569 , 0.9921569 , 0.9921569 , 0.9921569 , 0.76470596,\n",
      "       0.3137255 , 0.03529412, 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.21568629, 0.6745098 ,\n",
      "       0.8862746 , 0.9921569 , 0.9921569 , 0.9921569 , 0.9921569 ,\n",
      "       0.9568628 , 0.52156866, 0.04313726, 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.53333336, 0.9921569 , 0.9921569 , 0.9921569 ,\n",
      "       0.8313726 , 0.5294118 , 0.5176471 , 0.0627451 , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        ], dtype=float32), 5)\n"
     ]
    }
   ],
   "source": [
    "for x in haha:\n",
    "  print(x)\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "haha = input_sequence[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1368d3a90>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x129ccde80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(haha.reshape(28, 28), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "haha = list(input_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_labels_pairs_generator(subset='train'):\n",
    "  \"\"\"Get generator of (features, labels) pairs to be used for\n",
    "  dataset_formatter.UniMediaDatasetFormatter.\n",
    "  \"\"\"\n",
    "  datasets = mnist.read_data_sets(train_dir='/tmp/data/', validation_size=0)\n",
    "  if subset == 'train':\n",
    "    features = datasets.train.images\n",
    "    labels = datasets.train.labels\n",
    "  else:\n",
    "    features = datasets.test.images\n",
    "    labels = datasets.test.labels\n",
    "  print(\"features.shape: \", features.shape)\n",
    "  labels = [[x] for x in labels] # each item in labels should be a list\n",
    "  return lambda: zip(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
      "features.shape:  (60000, 784)\n"
     ]
    }
   ],
   "source": [
    "features_labels_pairs_train =\\\n",
    "      get_features_labels_pairs_generator(subset='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "haha = features_labels_pairs_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "for x in haha:\n",
    "  print(type(x[0]))\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "for haha in x[0]:\n",
    "  print(haha)\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "zip"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "haha = (x for x in features_labels_pairs_train())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "generator"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(haha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classes = ['zero', 'one', 'two', 'three', 'four',\n",
    "             'five', 'six', 'seven', 'eight', 'nine']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label_to_index_map_dict = {s:i for i, s in enumerate(classes)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zero\n",
      "one\n",
      "two\n",
      "three\n",
      "four\n",
      "five\n",
      "six\n",
      "seven\n",
      "eight\n",
      "nine\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dict_to_text_format(python_dict, map_name='label_to_index_map'):\n",
    "  template = \"\"\"<label_to_index_map> {\n",
    "  key: <key>\n",
    "  value: <value>\n",
    "}\n",
    "\"\"\"\n",
    "  template = template.replace('<label_to_index_map>', map_name)\n",
    "  text_format = ''\n",
    "  for k, v in python_dict.items():\n",
    "    item = template.replace('<key>', \"'\" + str(k) + \"'\")\n",
    "    item = item.replace('<value>', str(v))\n",
    "    text_format += item\n",
    "  return text_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label_to_index_map {\n",
      "  key: 'zero'\n",
      "  value: 0\n",
      "}\n",
      "label_to_index_map {\n",
      "  key: 'one'\n",
      "  value: 1\n",
      "}\n",
      "label_to_index_map {\n",
      "  key: 'two'\n",
      "  value: 2\n",
      "}\n",
      "label_to_index_map {\n",
      "  key: 'three'\n",
      "  value: 3\n",
      "}\n",
      "label_to_index_map {\n",
      "  key: 'four'\n",
      "  value: 4\n",
      "}\n",
      "label_to_index_map {\n",
      "  key: 'five'\n",
      "  value: 5\n",
      "}\n",
      "label_to_index_map {\n",
      "  key: 'six'\n",
      "  value: 6\n",
      "}\n",
      "label_to_index_map {\n",
      "  key: 'seven'\n",
      "  value: 7\n",
      "}\n",
      "label_to_index_map {\n",
      "  key: 'eight'\n",
      "  value: 8\n",
      "}\n",
      "label_to_index_map {\n",
      "  key: 'nine'\n",
      "  value: 9\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(dict_to_text_format(label_to_index_map_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<label_to_index_map> {\n",
      "  key: <key>\n",
      "  value: <value>\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR-100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Be sure to store CIFAR data in these locations\n",
    "root_dir = \"../../raw_datasets/image/cifar-100-python/\"\n",
    "metadata_file = root_dir + 'meta'\n",
    "train_file = root_dir + 'train'\n",
    "test_file = root_dir + 'test'\n",
    "metadata_dict = unpickle(metadata_file)\n",
    "train_dict = unpickle(train_file)\n",
    "test_dict = unpickle(test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys([b'fine_label_names', b'coarse_label_names'])\n",
      "dict_keys([b'filenames', b'batch_label', b'fine_labels', b'coarse_labels', b'data'])\n",
      "dict_keys([b'filenames', b'batch_label', b'fine_labels', b'coarse_labels', b'data'])\n"
     ]
    }
   ],
   "source": [
    "print(metadata_dict.keys())\n",
    "print(train_dict.keys())\n",
    "print(test_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 3072)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dict[b'data'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bytes"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dict[b'batch_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dict = train_dict\n",
    "images = data_dict[b'data']\n",
    "num_examples = images.shape[0]\n",
    "haha = images.reshape(num_examples, 3, 32, 32).transpose([0, 2, 3, 1])\n",
    "\n",
    "VECT = [0.299, 0.587, 0.114]\n",
    "res = haha.dot(VECT) # Convert to gray scale\n",
    "res = res.reshape(num_examples, 32*32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "coarse_labels = data_dict[b'coarse_labels']\n",
    "translation = len(coarse_label_names) # 20\n",
    "fine_labels = [x + translation for x in data_dict[b'fine_labels']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(coarse_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(fine_labels).min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 1024)"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-197-d8b18f67dbac>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-197-d8b18f67dbac>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    images.reshape(:, 3, 32, 32).transpose([0, 2, 3, 1])\u001b[0m\n\u001b[0m                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "images.reshape(:, 3, 32, 32).transpose([0, 2, 3, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = zip(coarse_labels, fine_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11, 39)\n"
     ]
    }
   ],
   "source": [
    "for x in labels:\n",
    "  print(x)\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'axis' is an invalid keyword argument for this function",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-184-1a467064031d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhahaha\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVECT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'axis' is an invalid keyword argument for this function"
     ]
    }
   ],
   "source": [
    "np.dot(VECT, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_label_names = metadata_dict[b'fine_label_names']\n",
    "fine_label_names = [x.decode('utf-8') for x in fine_label_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "coarse_label_names = metadata_dict[b'coarse_label_names']\n",
    "coarse_label_names = [x.decode('utf-8') for x in coarse_label_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(coarse_label_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_name = 'ciao'\n",
    "# train_dir = os.path.join(input_dir, '{}/{}.data/train'.format(dataset_name, dataset_name))\n",
    "test_dir = os.path.join(input_dir, '{}/{}.data/test'.format(dataset_name, dataset_name))\n",
    "dataset_dir = test_dir\n",
    "autodl_dataset = AutoDLDataset(dataset_dir, repeat=False)\n",
    "dataset = autodl_dataset.get_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_to_tfrecord = os.path.join(input_dir, '{}/{}.data/train/sample-{}-train.tfrecord'.format(dataset_name, dataset_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verification on TFRecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Copyright 2016 Google Inc. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#      http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS-IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "\"\"\"AutoDL datasets.\n",
    "\n",
    "Reads data in the Tensorflow AutoDL standard format.\n",
    "\"\"\"\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import app\n",
    "from tensorflow import flags\n",
    "from tensorflow import gfile\n",
    "from tensorflow import logging\n",
    "from google.protobuf import text_format\n",
    "import dataset_utils\n",
    "from data_pb2 import DataSpecification\n",
    "from data_pb2 import MatrixSpec\n",
    "\n",
    "# FLAGS = flags.FLAGS\n",
    "#\n",
    "# flags.DEFINE_string(\"dataset_dir\", \"\",\n",
    "#                     \"absolute path to data directory.\")\n",
    "#\n",
    "# def metadata_filename(dataset_name):\n",
    "#   return os.path.join(FLAGS.dataset_dir, dataset_name,\n",
    "#                       \"metadata.textproto\")\n",
    "#\n",
    "#\n",
    "# def dataset_file_pattern(dataset_name):\n",
    "#   return os.path.join(FLAGS.dataset_dir, dataset_name, \"sample*\")\n",
    "\n",
    "def metadata_filename(dataset_name):\n",
    "  return os.path.join(\"\", dataset_name,\n",
    "                      \"metadata.textproto\")\n",
    "\n",
    "\n",
    "def dataset_file_pattern(dataset_name):\n",
    "  return os.path.join(\"\", dataset_name, \"sample*\")\n",
    "\n",
    "\n",
    "class AutoDLMetadata(object):\n",
    "  \"\"\"AutoDL data specification.\"\"\"\n",
    "\n",
    "  def __init__(self, dataset_name):\n",
    "    self.dataset_name_ = dataset_name\n",
    "    self.metadata_ = DataSpecification()\n",
    "    with gfile.GFile(metadata_filename(dataset_name), \"r\") as f:\n",
    "      text_format.Merge(f.read(), self.metadata_)\n",
    "\n",
    "  def get_dataset_name(self):\n",
    "    return self.dataset_name_\n",
    "\n",
    "  def is_compressed(self, bundle_index):\n",
    "    return self.metadata_.matrix_spec[\n",
    "        bundle_index].format == MatrixSpec.COMPRESSED\n",
    "\n",
    "  def is_sparse(self, bundle_index):\n",
    "    return self.metadata_.matrix_spec[bundle_index].format == MatrixSpec.SPARSE\n",
    "\n",
    "  def get_bundle_size(self):\n",
    "    return len(self.metadata_.matrix_spec)\n",
    "\n",
    "  def get_matrix_size(self, bundle_index):\n",
    "    return (self.metadata_.matrix_spec[bundle_index].row_count,\n",
    "            self.metadata_.matrix_spec[bundle_index].col_count)\n",
    "\n",
    "  def get_sequence_size(self):\n",
    "    return self.metadata_.sequence_size\n",
    "\n",
    "  def get_output_size(self):\n",
    "    return self.metadata_.output_dim\n",
    "\n",
    "  def size(self):\n",
    "    return self.metadata_.sample_count\n",
    "\n",
    "\n",
    "class AutoDLDataset(object):\n",
    "  \"\"\"AutoDL Datasets out of TFRecords of SequenceExamples.\n",
    "\n",
    "     See cs///experimental/autodl/export/tensorflow/README.md for more details\n",
    "     on the features and labels.\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self, dataset_name, repeat=True):\n",
    "    \"\"\"Construct an AutoDL Dataset.\n",
    "\n",
    "    Args:\n",
    "      dataset_name: name of the dataset under the 'dataset_dir' flag.\n",
    "    \"\"\"\n",
    "    self.dataset_name_ = dataset_name\n",
    "    self.metadata_ = AutoDLMetadata(dataset_name)\n",
    "    self._create_dataset()\n",
    "    self.dataset_ = self.dataset_.map(self._parse_function)\n",
    "    # self.dataset_ = self.dataset_.batch(batch_size)\n",
    "    if repeat:\n",
    "      self.dataset_ = self.dataset_.repeat()\n",
    "\n",
    "  def get_dataset(self):\n",
    "    \"\"\"Returns a tf.data.dataset object.\"\"\"\n",
    "    return self.dataset_\n",
    "\n",
    "  def get_metadata(self):\n",
    "    \"\"\"Returns an AutoDLMetadata object.\"\"\"\n",
    "    return self.metadata_\n",
    "\n",
    "  def _feature_key(self, index, feature_name):\n",
    "    return str(index) + \"_\" + feature_name\n",
    "\n",
    "  def _parse_function(self, sequence_example_proto):\n",
    "    \"\"\"Parse a SequenceExample in the AutoDL/TensorFlow format.\n",
    "\n",
    "    Args:\n",
    "      sequence_example_proto: a SequenceExample with \"x_dense_input\" or sparse\n",
    "          input representation.\n",
    "    Returns:\n",
    "      An array of tensors.\n",
    "    \"\"\"\n",
    "    sequence_features = {}\n",
    "    for i in range(self.metadata_.get_bundle_size()):\n",
    "      if self.metadata_.is_sparse(i):\n",
    "        sequence_features[self._feature_key(\n",
    "            i, \"sparse_col_index\")] = tf.VarLenFeature(tf.int64)\n",
    "        sequence_features[self._feature_key(\n",
    "            i, \"sparse_row_index\")] = tf.VarLenFeature(tf.int64)\n",
    "        sequence_features[self._feature_key(\n",
    "            i, \"sparse_value\")] = tf.VarLenFeature(tf.float32)\n",
    "      elif self.metadata_.is_compressed(i):\n",
    "        sequence_features[self._feature_key(\n",
    "            i, \"compressed\")] = tf.VarLenFeature(tf.string)\n",
    "      else:\n",
    "        sequence_features[self._feature_key(\n",
    "            i, \"dense_input\")] = tf.FixedLenSequenceFeature(\n",
    "                self.metadata_.get_matrix_size(i), dtype=tf.float32)\n",
    "    contexts, features = tf.parse_single_sequence_example(\n",
    "        sequence_example_proto,\n",
    "        context_features={\n",
    "            \"label_index\": tf.VarLenFeature(tf.int64),\n",
    "            \"label_score\": tf.VarLenFeature(tf.float32),\n",
    "            \"id\": tf.FixedLenFeature(1, dtype=tf.int64),\n",
    "        },\n",
    "        sequence_features=sequence_features)\n",
    "\n",
    "    sample = []\n",
    "    for i in range(self.metadata_.get_bundle_size()):\n",
    "      key_dense = self._feature_key(i, \"dense_input\")\n",
    "      row_count, col_count = self.metadata_.get_matrix_size(i)\n",
    "      if key_dense in features:\n",
    "        f = features[key_dense]\n",
    "        sample.append(tf.reshape(f, [-1, row_count, col_count]))\n",
    "\n",
    "      key_compressed = self._feature_key(i, \"compressed\")\n",
    "      if key_compressed in features:\n",
    "        compressed_images = features[key_compressed].values\n",
    "        images = tf.map_fn(\n",
    "            dataset_utils.decompress_image, compressed_images, dtype=tf.float32)\n",
    "        sample.append(tf.reshape(images, [-1, row_count, col_count]))\n",
    "\n",
    "      key_sparse_val = self._feature_key(i, \"sparse_value\")\n",
    "      if key_sparse_val in features:\n",
    "        key_sparse_col = self._feature_key(i, \"sparse_col_index\")\n",
    "        key_sparse_row = self._feature_key(i, \"sparse_row_index\")\n",
    "        sparse_col = features[key_sparse_col].values\n",
    "        sparse_row = features[key_sparse_row].values\n",
    "        sparse_val = features[key_sparse_val]\n",
    "        indices = sparse_val.indices\n",
    "        indices = tf.concat([\n",
    "            tf.reshape(indices[:, 0], [-1, 1]),\n",
    "            tf.reshape(sparse_row, [-1, 1]),\n",
    "            tf.reshape(sparse_col, [-1, 1])\n",
    "        ], 1)\n",
    "        sparse_tensor = tf.sparse_reorder(\n",
    "            tf.SparseTensor(\n",
    "                indices, sparse_val.values,\n",
    "                [self.metadata_.get_sequence_size(), row_count, col_count]))\n",
    "        # TODO: see how we can keep sparse tensors instead of\n",
    "        # returning dense ones.\n",
    "        sample.append(tf.sparse_tensor_to_dense(sparse_tensor))\n",
    "\n",
    "    # Enforce the Sample tensors to have the correct sequence length.\n",
    "    sequence_size = self.metadata_.get_sequence_size()\n",
    "    sample = [\n",
    "        dataset_utils.enforce_sequence_size(t, sequence_size) for t in sample\n",
    "    ]\n",
    "\n",
    "    labels = tf.sparse_to_dense(\n",
    "        contexts[\"label_index\"].values, (self.metadata_.get_output_size(),),\n",
    "        contexts[\"label_score\"].values,\n",
    "        validate_indices=False)\n",
    "    sample.append(contexts[\"id\"])\n",
    "    sample.append(labels)\n",
    "    return sample\n",
    "\n",
    "  def _create_dataset(self):\n",
    "    if not hasattr(self, \"dataset_\"):\n",
    "      files = gfile.Glob(dataset_file_pattern(self.dataset_name_))\n",
    "      if not files:\n",
    "        raise IOError(\"Unable to find training files. data_pattern='\" +\n",
    "                      dataset_file_pattern(self.dataset_name_) + \"'.\")\n",
    "      logging.info(\"Number of training files: %s.\", str(len(files)))\n",
    "      self.dataset_ = tf.data.TFRecordDataset(files)\n",
    "\n",
    "  # def init(self, batch_size=30, repeat=True):\n",
    "  #   self._create_dataset()\n",
    "  #   self.dataset_ = self.dataset_.map(self._parse_function)\n",
    "  #   # self.dataset_ = self.dataset_.batch(batch_size)\n",
    "  #   if repeat:\n",
    "  #     self.dataset_ = self.dataset_.repeat()\n",
    "\n",
    "\n",
    "def main(argv):\n",
    "  del argv  # Unused.\n",
    "  dataset = AutoDLDataset(\"mnist\")\n",
    "  dataset.init()\n",
    "  iterator = dataset.get_dataset().make_one_shot_iterator()\n",
    "  next_element = iterator.get_next()\n",
    "\n",
    "  sess = tf.Session()\n",
    "  for idx in range(10):\n",
    "    print(\"Example \" + str(idx))\n",
    "    print(sess.run(next_element))\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#   app.run(main)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Number of training files: 1.\n"
     ]
    }
   ],
   "source": [
    "dataset_name = 'ciao'\n",
    "# train_dir = os.path.join(input_dir, '{}/{}.data/train'.format(dataset_name, dataset_name))\n",
    "test_dir = os.path.join(input_dir, '{}/{}.data/test'.format(dataset_name, dataset_name))\n",
    "dataset_dir = test_dir\n",
    "autodl_dataset = AutoDLDataset(dataset_dir, repeat=False)\n",
    "dataset = autodl_dataset.get_dataset()\n",
    "iterator = dataset.make_one_shot_iterator()\n",
    "next_element = iterator.get_next()\n",
    "features, labels = next_element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[114.091995 110.27699  109.27699  ... 128.681    128.98     133.062   ]\n",
      "  [109.41901  107.533005 108.935    ... 140.21     140.808    144.716   ]\n",
      "  [127.084    120.41499  118.746    ... 148.021    147.733    150.342   ]\n",
      "  ...\n",
      "  [ 24.335     23.705002  19.776001 ... 112.614     73.966995  46.212006]\n",
      "  [ 22.591003  17.074997   8.733002 ... 115.90199   79.938995  37.824997]\n",
      "  [ 12.733002   8.031998   6.102997 ... 110.90199   99.825     69.754   ]]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "  for i in range(1):\n",
    "    ele = sess.run(tf.abs(features - 100))\n",
    "    print(ele)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Number of training files: 1.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] [01:19:48:tensorflow] Number of training files: 1.\n"
     ]
    }
   ],
   "source": [
    "dataset_name = 'ciao'\n",
    "train_dir = os.path.join(input_dir, '{}/{}.data/train'.format(dataset_name, dataset_name))\n",
    "test_dir = os.path.join(input_dir, '{}/{}.data/test'.format(dataset_name, dataset_name))\n",
    "dataset_dir = train_dir\n",
    "autodl_dataset = AutoDLDataset(dataset_dir, repeat=False)\n",
    "dataset = autodl_dataset.get_dataset()\n",
    "iterator = dataset.make_one_shot_iterator()\n",
    "next_element = iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<RepeatDataset shapes: ((1, 32, 32), (120,)), types: (tf.float32, tf.float32)>"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "42000\n",
      "43000\n",
      "44000\n",
      "45000\n",
      "46000\n",
      "47000\n",
      "48000\n",
      "49000\n",
      "50000\n",
      "The End. 50000\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "X_train = []\n",
    "Y_train = []\n",
    "with tf.Session() as sess:\n",
    "  while True:\n",
    "    try:\n",
    "      features, labels = sess.run(next_element)\n",
    "      X_train.append(features.flatten())\n",
    "      Y_train.append(labels.flatten())\n",
    "      counter += 1\n",
    "      if counter % 1000 == 0:\n",
    "        print(counter)\n",
    "    except tf.errors.OutOfRangeError:\n",
    "      print(\"The End.\", counter)\n",
    "      break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)\n",
    "Y_train = np.array(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 1024)"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 120)"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Number of training files: 1.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] [01:20:47:tensorflow] Number of training files: 1.\n"
     ]
    }
   ],
   "source": [
    "dataset_name = 'ciao'\n",
    "train_dir = os.path.join(input_dir, '{}/{}.data/train'.format(dataset_name, dataset_name))\n",
    "test_dir = os.path.join(input_dir, '{}/{}.data/test'.format(dataset_name, dataset_name))\n",
    "dataset_dir = test_dir\n",
    "autodl_dataset = AutoDLDataset(dataset_dir, repeat=False)\n",
    "dataset = autodl_dataset.get_dataset()\n",
    "iterator = dataset.make_one_shot_iterator()\n",
    "next_element = iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "The End. 10000\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "X_test = []\n",
    "with tf.Session() as sess:\n",
    "  while True:\n",
    "    try:\n",
    "      features, labels = sess.run(next_element)\n",
    "      X_test.append(features.flatten())\n",
    "      counter += 1\n",
    "      if counter % 1000 == 0:\n",
    "        print(counter)\n",
    "    except tf.errors.OutOfRangeError:\n",
    "      print(\"The End.\", counter)\n",
    "      break\n",
    "X_test = np.array(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Uncomment the right line in the following:\n",
    "from autosklearn.classification import AutoSklearnClassifier\n",
    "\n",
    "M = AutoSklearnClassifier(time_left_for_this_task=60, per_run_time_limit=10) # Change the time budget!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/evariste/anaconda3/lib/python3.6/site-packages/autosklearn/pipeline/create_searchspace_util.py:123: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  if np.sum(matches[slices]) > 0:\n",
      "/Users/evariste/anaconda3/lib/python3.6/site-packages/autosklearn/pipeline/create_searchspace_util.py:208: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  if np.sum(matches[slices_]) == 0:\n",
      "/Users/evariste/anaconda3/lib/python3.6/site-packages/autosklearn/pipeline/create_searchspace_util.py:228: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  if np.sum(matches[slices]) == 0:\n",
      "/Users/evariste/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/evariste/anaconda3/lib/python3.6/site-packages/autosklearn/pipeline/create_searchspace_util.py:123: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  if np.sum(matches[slices]) > 0:\n",
      "/Users/evariste/anaconda3/lib/python3.6/site-packages/autosklearn/pipeline/create_searchspace_util.py:208: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  if np.sum(matches[slices_]) == 0:\n",
      "/Users/evariste/anaconda3/lib/python3.6/site-packages/autosklearn/pipeline/create_searchspace_util.py:228: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  if np.sum(matches[slices]) == 0:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] [2018-10-17 01:26:37,819:smac.intensification.intensification.Intensifier] Challenger was the same as the current incumbent; Skipping challenger\n",
      "[WARNING] [2018-10-17 01:26:37,819:smac.intensification.intensification.Intensifier] Challenger was the same as the current incumbent; Skipping challenger\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/evariste/anaconda3/lib/python3.6/site-packages/autosklearn/pipeline/create_searchspace_util.py:123: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  if np.sum(matches[slices]) > 0:\n",
      "/Users/evariste/anaconda3/lib/python3.6/site-packages/autosklearn/pipeline/create_searchspace_util.py:208: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  if np.sum(matches[slices_]) == 0:\n",
      "/Users/evariste/anaconda3/lib/python3.6/site-packages/autosklearn/pipeline/create_searchspace_util.py:228: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  if np.sum(matches[slices]) == 0:\n",
      "/Users/evariste/anaconda3/lib/python3.6/site-packages/autosklearn/pipeline/create_searchspace_util.py:123: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  if np.sum(matches[slices]) > 0:\n",
      "/Users/evariste/anaconda3/lib/python3.6/site-packages/autosklearn/pipeline/create_searchspace_util.py:208: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  if np.sum(matches[slices_]) == 0:\n",
      "/Users/evariste/anaconda3/lib/python3.6/site-packages/autosklearn/pipeline/create_searchspace_util.py:228: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  if np.sum(matches[slices]) == 0:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] [2018-10-17 01:26:56,003:smac.intensification.intensification.Intensifier] Challenger was the same as the current incumbent; Skipping challenger\n",
      "[WARNING] [2018-10-17 01:26:56,003:smac.intensification.intensification.Intensifier] Challenger was the same as the current incumbent; Skipping challenger\n",
      "[WARNING] [2018-10-17 01:26:56,011:smac.intensification.intensification.Intensifier] Challenger was the same as the current incumbent; Skipping challenger\n",
      "[WARNING] [2018-10-17 01:26:56,011:smac.intensification.intensification.Intensifier] Challenger was the same as the current incumbent; Skipping challenger\n",
      "[WARNING] [2018-10-17 01:26:56,016:smac.intensification.intensification.Intensifier] Challenger was the same as the current incumbent; Skipping challenger\n",
      "[WARNING] [2018-10-17 01:26:56,016:smac.intensification.intensification.Intensifier] Challenger was the same as the current incumbent; Skipping challenger\n",
      "[WARNING] [2018-10-17 01:26:56,021:smac.intensification.intensification.Intensifier] Challenger was the same as the current incumbent; Skipping challenger\n",
      "[WARNING] [2018-10-17 01:26:56,021:smac.intensification.intensification.Intensifier] Challenger was the same as the current incumbent; Skipping challenger\n",
      "[WARNING] [2018-10-17 01:26:56,027:smac.intensification.intensification.Intensifier] Challenger was the same as the current incumbent; Skipping challenger\n",
      "[WARNING] [2018-10-17 01:26:56,027:smac.intensification.intensification.Intensifier] Challenger was the same as the current incumbent; Skipping challenger\n",
      "[WARNING] [2018-10-17 01:26:56,035:smac.intensification.intensification.Intensifier] Challenger was the same as the current incumbent; Skipping challenger\n",
      "[WARNING] [2018-10-17 01:26:56,035:smac.intensification.intensification.Intensifier] Challenger was the same as the current incumbent; Skipping challenger\n",
      "[WARNING] [2018-10-17 01:26:56,039:smac.intensification.intensification.Intensifier] Challenger was the same as the current incumbent; Skipping challenger\n",
      "[WARNING] [2018-10-17 01:26:56,039:smac.intensification.intensification.Intensifier] Challenger was the same as the current incumbent; Skipping challenger\n",
      "[WARNING] [2018-10-17 01:26:56,044:smac.intensification.intensification.Intensifier] Challenger was the same as the current incumbent; Skipping challenger\n",
      "[WARNING] [2018-10-17 01:26:56,044:smac.intensification.intensification.Intensifier] Challenger was the same as the current incumbent; Skipping challenger\n",
      "[WARNING] [2018-10-17 01:26:56,053:smac.intensification.intensification.Intensifier] Challenger was the same as the current incumbent; Skipping challenger\n",
      "[WARNING] [2018-10-17 01:26:56,053:smac.intensification.intensification.Intensifier] Challenger was the same as the current incumbent; Skipping challenger\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/evariste/anaconda3/lib/python3.6/site-packages/autosklearn/smbo.py:671: RuntimeWarning: invalid value encountered in true_divide\n",
      "  (1. - dataset_minimum))\n",
      "/Users/evariste/anaconda3/lib/python3.6/site-packages/autosklearn/smbo.py:672: RuntimeWarning: invalid value encountered in greater\n",
      "  Y_cfg[:, 0][Y_cfg[:, 0] > 2] = 2\n",
      "/Users/evariste/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater\n",
      "  return (self.a < x) & (x < self.b)\n",
      "/Users/evariste/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less\n",
      "  return (self.a < x) & (x < self.b)\n",
      "/Users/evariste/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1738: RuntimeWarning: invalid value encountered in greater_equal\n",
      "  cond2 = (x >= self.b) & cond0\n",
      "/Users/evariste/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:876: RuntimeWarning: invalid value encountered in greater_equal\n",
      "  return (self.a <= x) & (x <= self.b)\n",
      "/Users/evariste/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:876: RuntimeWarning: invalid value encountered in less_equal\n",
      "  return (self.a <= x) & (x <= self.b)\n",
      "/Users/evariste/anaconda3/lib/python3.6/site-packages/smac/optimizer/acquisition.py:165: RuntimeWarning: invalid value encountered in less\n",
      "  if (f < 0).any():\n"
     ]
    }
   ],
   "source": [
    "M.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_hat_test = M.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 120)"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_hat_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(Y_hat_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/evariste/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "from autosklearn.classification import AutoSklearnClassifier as Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
